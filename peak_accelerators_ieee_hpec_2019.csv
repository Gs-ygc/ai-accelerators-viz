Company,Product,Label,PeakPerformance,Precision,Power,Technology,IorT,FormFactor,PlotLocation,Hide,AI Model,Updated,Notes,ReferenceURL,Reference
NVIDIA,Tesla K80,K80,8.74E+12,float,300,GPU,Training,Card,SE,,Raw FLOPS,9/21/18,Power and performance numbers are from table on the anandtech web page,https://www.anandtech.com/show/8729/nvidia-launches-tesla-k80-gk210-gpu,
NVIDIA,Pascal NVMe,P100,2.12E+13,half,300,GPU,Training,Card,SE,,,9/21/18,Power and performance numbers are from table on the nvidia and anandtech web pages,https://www.nvidia.com/en-us/data-center/tesla-p100/;https://www.anandtech.com/show/12809/16gb-nvidia-tesla-v100-gets-reprieve-remains-in-production,
NVIDIA,Volta NVMe,V100,1.25E+14,AI,300,GPU,Training,Card,SE,,,9/21/18,Power and performance numbers are from table on the nvidia and anandtech web pages,https://www.nvidia.com/en-us/data-center/tesla-v100/;https://www.anandtech.com/show/12809/16gb-nvidia-tesla-v100-gets-reprieve-remains-in-production,
NVIDIA,DGX-1,DGX-1,9.60E+14,AI,3500,GPU,Training,System,SE,,,10/2/18,Power and performance numbers are from table on the anandtech web page,https://www.anandtech.com/show/12587/nvidias-dgx2-sixteen-v100-gpus-30-tb-of-nvme-only-400k,
NVIDIA,DGX-2,DGX-2,1.92E+15,AI,10000,GPU,Training,System,SE,,,10/2/18,Power and performance numbers are from table on the anandtech web page,https://www.anandtech.com/show/12587/nvidias-dgx2-sixteen-v100-gpus-30-tb-of-nvme-only-400k,
NVIDIA,DGX Station,DGX-Station,4.80E+14,AI,1500,GPU,Training,System,SE,,,10/2/18,Workstation with 4 x Tesla V100. Performance and power numbers are on cluster vision web page.,https://clustervision.com/solutions/cluster-design/nvidia-dgx-station/,
NVIDIA,Jetson1,Jetson1,4.08E+11,AI,11.7,GPU,Inference,System,SE,,,10/2/18,Denver-based Maxwell GPU (ARMs + GPU). Performance numbers on nvidia blog page. ,https://devblogs.nvidia.com/jetson-tx2-delivers-twice-intelligence-edge/,
NVIDIA,Jetson2,Jetson2,5.80E+11,AI,12.8,GPU,Inference,System,SE,,,10/2/18,Parker = Pascal-based GPU. Performance numbers on nvidia blog page. ,https://devblogs.nvidia.com/jetson-tx2-delivers-twice-intelligence-edge/,
NVIDIA,Jetson Xavier,Xavier,1.00E+13,half,30,GPU,Inference,System,SE,,,10/2/18,Tegra processor with Volta for automotive market. Performance and power numbers from the extremetech web page. ,https://www.extremetech.com/computing/270681-nvidias-jetson-xavier-stuffs-volta-performance-into-tiny-form-factor,
NVIDIA,Turing Quadro RTX 6000,Turing,1.31E+14,int8,260,GPU,Inference,Card,SE,,Raw FLOPS,10/24/18,Reported TDP and FLOPS from Blog post (ref 1).,https://devblogs.nvidia.com/nvidia-turing-architecture-in-depth/,
GraphCore,C2,GraphCoreC2,5.00E+12,AI,300,dataflow,Training,Card,SE,,,10/1/18,GraphCore preliminary benchmarking web page has stats for a single C2 IPU accelerator and 8 C2 IPUs. ,https://www.graphcore.ai/posts/preliminary-ipu-benchmarks-providing-previously-unseen-performance-for-a-range-of-machine-learning-applications;https://github.com/albanie/convnet-burden,
GraphCore,C2,GraphCoreNode,3.20E+13,AI,2400,dataflow,Training,System,SE,,,10/1/18,GraphCore preliminary benchmarking web page has stats for a single C2 IPU accelerator and 8 C2 IPUs. ,https://www.graphcore.ai/posts/preliminary-ipu-benchmarks-providing-previously-unseen-performance-for-a-range-of-machine-learning-applications;https://github.com/albanie/convnet-burden,
Wave Computing,DPU,Wave DPU,1.80E+14,AI,300,dataflow,Inference,Card,SE,,,10/3/18,4-DPU compute card. Stats from next platform web page. Using ,https://www.nextplatform.com/2017/08/23/first-depth-view-wave-computings-dpu-architecture-systems/;https://github.com/albanie/convnet-burden,
Wave Computing,DPU,Wave System,2.90E+15,AI,2700,dataflow,Inference,System,SE,,,10/3/18,3-U 16-DPU compute node,https://www.top500.org/news/wave-computing-launches-machine-learning-appliance/;https://github.com/albanie/convnet-burden,
Intel,Xeon Phi 7210F,Phi7210F,2.66E+12,double,230,manycore,Training,Chip,SE,,,9/21/18,,https://en.wikipedia.org/wiki/Xeon_Phi,
Intel,Xeon Phi 7290F,Phi7290F,3.46E+12,double,260,manycore,Training,Chip,SE,,,9/21/18,,https://en.wikipedia.org/wiki/Xeon_Phi,
Intel,Xeon Skylake SP (Scalable),2xSkylakeSP,2.62E+12,float,410,manycore,Inference,Chip,SE,,,10/3/18,,https://software.intel.com/en-us/articles/intel-processors-for-deep-learning-training;https://ark.intel.com/products/120496/Intel-Xeon-Platinum-8180-Processor-38-5M-Cache-2-50-GHz-,
Intel,Nervana Lake Crest,Nervana1,3.80E+13,float,210,manycore,Training,Card,SE,,Raw FLOPS,10/1/18,Peak matrix multiply performance,https://newsroom.intel.com/editorials/artificial-intelligence-requires-holistic-approach/;https://www.hpcwire.com/2018/05/24/intel-pledges-first-commercial-nervana-product-spring-crest-in-2019/;https://www.top500.org/news/intel-lays-out-new-roadmap-for-ai-portfolio/,
Intel,Nervana NNP L-1000 (Spring Crest),Nervana2,1.20E+14,AI,210,manycore,Training,Card,SE,,Raw FLOPS,10/1/18,Peak bfloat16 matrix multiply performance,https://newsroom.intel.com/editorials/artificial-intelligence-requires-holistic-approach/;https://www.hpcwire.com/2018/05/24/intel-pledges-first-commercial-nervana-product-spring-crest-in-2019/;https://www.top500.org/news/intel-lays-out-new-roadmap-for-ai-portfolio/,
Intel,Movidius Myriad X,MovidiusX,1.00E+12,int16,2,manycore,Video,Chip,SE,,,10/1/18,"Movidius X has a Neural Engine. GoogleNet, batch size = 1",https://www.extremetech.com/computing/254772-new-movidius-myriad-x-vpu-packs-custom-neural-compute-engine;https://thenewstack.io/a-closer-look-at-intel-movidius-neural-compute-stick/,
Intel,Arria 10 1150,Arria,2.83E+14,AI,85,FPGA,Inference,Chip,SE,,,10/1/18,,https://arxiv.org/abs/1807.06434;https://www.nextplatform.com/2018/07/31/intel-fpga-architecture-focuses-on-deep-learning-inference/,
Habana,Goya HL-1000,Goya,5.70E+13,AI,100,dataflow,Inference,Chip,SE,,,9/26/18,,https://www.top500.org/news/ai-startup-sets-high-water-mark-with-new-inference-accelerator/;https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf,
Google,TPU1,TPU1,2.30E+13,int16,40,dataflow,Inference,Chip,SE,,,10/2/18,,https://www.nextplatform.com/2018/05/10/tearing-apart-googles-tpu-3-0-ai-coprocessor/,
Google,TPU2,TPU2,4.50E+13,AI,250,dataflow,Training,Chip,SE,,,10/2/18,,https://www.nextplatform.com/2018/05/10/tearing-apart-googles-tpu-3-0-ai-coprocessor/,
Google,TPU3,TPU3,9.00E+13,AI,200,dataflow,Training,Chip,SE,,,10/2/18,,https://www.nextplatform.com/2018/05/10/tearing-apart-googles-tpu-3-0-ai-coprocessor/,
Google,TPU Edge,TPUedge,5.85E+10,AI,2,dataflow,Inference,System,SE,,MobileNetV2,10/9/02,withgoogle.com URL says 100+ fps with MobileNetv2; MobileNetV2 ArXiv paper quotes 585 Mops per image for inference; power is similar to raspberry pi which is less than 2W,https://aiyprojects.withgoogle.com/edge-tpu,
MIT,Eyeriss,Eyeriss,3.27E+10,AI,0.45,dataflow,Inference,Chip,SE,,,10/2/18,,https://ieeexplore.ieee.org/document/7738524;https://github.com/albanie/convnet-burden,
IBM,TrueNorth,TrueNorth,1.89E+12,int8,0.5,neuromorphic,Inference,System,SE,,,10/2/18,,https://www.top500.org/news/ibm-finds-killer-app-for-truenorth-neuromorphic-chip/;https://github.com/albanie/convnet-burden,
IBM,TrueNorth,TrueNorth,1.89E+12,int8,44,neuromorphic,Inference,System,SE,,,10/2/18,,https://www.top500.org/news/ibm-finds-killer-app-for-truenorth-neuromorphic-chip/;https://github.com/albanie/convnet-burden,
Rockchip,RK3399Pro,RK3399Pro,2.40E+12,8bit,3,dataflow,Inference,Chip,SE,,Raw FLOPS,10/3/18,,http://www.rock-chips.com/a/en/News/Press_Releases/2018/0108/869.html;https://www.cnx-software.com/2018/01/08/rockchip-rk3399pro-soc-integrates-a-2-4-tops-neural-network-processing-unit-for-artificial-intelligence-applications/,
Baidu,Baidu Kunlun 818-300,Baidu,2.60E+14,AI,100,dataflow,Training,Chip,SE,,Raw FLOPS,2/5/19,Baidu claims the FLOPs and power numbers in the zdnet article. The chip has been deployed in Baidu data centers as FPGAs and are being converted to ASICs. No release data has been mentioned in the press. ,https://www.eetimes.com/document.asp?doc_id=1333449;https://www.zdnet.com/article/baidu-creates-kunlun-silicon-for-ai/,
AIStorm,AIStorm,AIStorm,2.50E+12,int8,0.227,dataflow,Inference,Chip,SE,,Raw OPS,2/11/19,Claim to do some of the math up at the sensor in analog domain. Originally came to the embedded space scene with biometric sensors and processing.,https://www.eetimes.com/document.asp?doc_id=1334301,
Xilinx / Tokyo Tech,Zynq XC7Z020,Zynq-020,3.30E+11,1-bit,2.3,Dataflow/FPGA,Inference,System,SE,,VGG-11,2/5/19,,https://arxiv.org/abs/1712.08934v3;https://ieeexplore.ieee.org/document/8056771,
Intel / Univ Sydney,GX1155,GX1155,4.08E+13,1-bit,48,Dataflow/FPGA,Inference,System,SE,,"Alexnet, VGGNet",2/7/19,,https://arxiv.org/abs/1712.08934v3;https://ieeexplore.ieee.org/document/8056823,
Fudan Univ,Zynq XC7Z020,Zynq-020,4.10E+11,2-bit,2.26,Dataflow/FPGA,Inference,System,SE,,DoReFa-Net,2/11/19,Imagenet data set,https://arxiv.org/abs/1712.08934v3;https://ieeexplore.ieee.org/document/8056820,
Xilinx / Tsinghua U,Zynq XC7Z020,Zynq-020,8.43E+10,int8,3.5,Dataflow/FPGA,Inference,System,SE,,VGG-11,2/11/19,Paper compares a couple of Zinq FPGAs with VGG-11 and YOLO,https://arxiv.org/abs/1712.08934v3;https://ieeexplore.ieee.org/document/7930521,
ASU / Intel,Intel Arria 10 GX1150,Arria 10,6.45E+11,int16/int8,21.2,Dataflow/FPGA,Inference,System,SE,,VGG-16,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://dl.acm.org/citation.cfm?id=3021736,
DeePhi / Stanford / Xilinx,Xilinx XCKU060,Zynq-060,2.52E+12,int16/int12,41,Dataflow/FPGA,Inference,System,SE,,LSTM with TIMIT Speech dataset,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://dl.acm.org/citation.cfm?id=3021745,
Peking Univ / UCLA / Xilinx,Xilinx XC7Z020 + XCV7VX620Tx6,XilinxCluster,1.28E+12,int16,160,Dataflow/FPGA,Inference,System,SE,,VGG-16,2/11/19,7 FPGA cluster design,https://arxiv.org/abs/1712.08934v3;https://dl.acm.org/citation.cfm?id=2934644,
Univ Wisconsin / Intel,Intel Arria 10 GX1150,Arria 10,1.79E+12,int16,37.46,Dataflow/FPGA,Inference,System,SE,,VGG-19,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://dl.acm.org/citation.cfm?id=3021698,
Peking Univ / Xilinx,Xilinx ZCU102,ZCU102,2.94E+12,int16,23.6,Dataflow/FPGA,Inference,System,SE,,VGG-16,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://ieeexplore.ieee.org/document/7966660,
Intel,Intel Arria 10 GX1150,Arria 10,1.38E+12,fp16,45,Dataflow/FPGA,Inference,System,SE,,Alexnet,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://dl.acm.org/citation.cfm?id=3021738,
USC / Intel,Stratix-V,Stratix-V,2.29E+11,int32,8.04,Dataflow/FPGA,Inference,System,SE,,VGG-16,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://ieeexplore.ieee.org/document/7995253,
Univ Wisconsin / Intel,Intel Arria 10 GX1150,Arria 10,8.66E+11,float,41.73,Dataflow/FPGA,Inference,System,SE,,VGG-19,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://dl.acm.org/citation.cfm?id=3021698,
Cambricon,Cambricon MLU-100,Cambricon,1.66E+14,int8,110,Dataflow,Inference,Chip,SE,,Raw OPS,2/13/19,Chinese chip company behind Huawai's Kirin NPU IP,https://www.anandtech.com/show/12815/cambricon-makers-of-huaweis-kirin-npu-ip-build-a-big-ai-chip-and-pcie-card;https://ieeexplore.ieee.org/document/7551409,
Cambricon,Cambricon MLU-100,Cambricon,8.32E+13,fp16,110,Dataflow,Training,Chip,SE,,Raw FLOPS,2/13/19,Chinese chip company behind Huawai's Kirin NPU IP,https://www.anandtech.com/show/12815/cambricon-makers-of-huaweis-kirin-npu-ip-build-a-big-ai-chip-and-pcie-card;https://ieeexplore.ieee.org/document/7551409,
DianNao,DianNao,DianNao,4.52E+11,int16,0.485,Dataflow,Inference,Chip,SE,,Raw FLOPS,,,https://cacm.acm.org/magazines/2016/11/209123-diannao-family/,
DianNao,DaDianNao,DaDianNao,5.59E+12,int16,15.97,Dataflow,Inference,Chip,SE,,Raw FLOPS,,,https://cacm.acm.org/magazines/2016/11/209123-diannao-family/,
DianNao,ShiDianNao,ShiDianNao,1.94E+11,int16,0.32,Dataflow,Inference,Chip,SE,,Raw FLOPS,,,https://cacm.acm.org/magazines/2016/11/209123-diannao-family/,
DianNao,PuDianNao,PuDianNao,1.06E+12,int16,0.596,Dataflow,Inference,Chip,SE,,Raw FLOPS,,,https://cacm.acm.org/magazines/2016/11/209123-diannao-family/,
Apple,Apple A12 Neural Engine,A12,6.24E+11,int8,5.5,GPU,Inference,System,SE,,VGG-16,2/13/19,Found good numbers on AnandTech from AIMark benchmarking in China,https://www.anandtech.com/show/13392/the-iphone-xs-xs-max-review-unveiling-the-silicon-secrets/5;https://medium.com/syncedreview/ai-chip-duel-apple-a12-bionic-vs-huawei-kirin-980-ec29cfe68632,
Qualcomm,Snapdragon 845,S845,2.00E+11,int8,5.01,GPU,Inference,System,SE,,InceptionV3,2/13/19,Found good numbers on AnandTech from AIMark benchmarking in China,https://www.anandtech.com/show/12520/the-galaxy-s9-review/6,
QualComm,Snapdragon 835,S835,1.30E+11,int8,3.79,GPU,Inference,System,SE,,ResNet34,2/13/19,Found good numbers on AnandTech from AIMark benchmarking in China,https://www.anandtech.com/show/12520/the-galaxy-s9-review/6,
Huawei,Kirin 970 (Mali--75),Mali-75,2.61E+11,int8,6.33,GPU,Inference,System,SE,,VGG-16,2/13/19,Found good numbers on AnandTech from AIMark benchmarking in China,https://www.anandtech.com/show/12520/the-galaxy-s9-review/6,
Huawei,Kirin 980 (Mali-76),Mali-76,4.68E+11,int8,5,GPU,Inference,System,SE,,ResNet34,2/13/19,Found good numbers on AnandTech from AIMark benchmarking in China,https://www.anandtech.com/show/13298/hisilicon-announces-the-kirin-980-first-a76-g76-on-7nm/2,
Groq,Groq,Groq,4.00E+14,int16,300,dataflow,Inference,Card,SE,,Raw FLOPS,3/12/19,Founded by Google TPU1 designers,https://www.electronicdesign.com/industrial-automation/groq-outlines-potential-power-artificial-intelligence-chip,
AMD,Radeon Instinct MI60,AMD-MI60,2.95E+13,fp16,300,GPU,Training,Card,SE,,Raw FLOPS,5/2/19,https://www.amd.com/en/graphics/servers-radeon-instinct-mi,https://www.amd.com/en/graphics/servers-radeon-instinct-mi,
AMD,Radeon Instinct MI6,AMD-MI6,5.73E+12,fp16,150,GPU,Inference,Card,SE,,Raw FLOPS,5/2/19,https://www.amd.com/en/graphics/servers-radeon-instinct-mi,https://www.amd.com/en/graphics/servers-radeon-instinct-mi,
Tesla,Tesla Full Self-Driving Computer,Tesla,7.20E+13,int8,72,,,,SE,,,,https://www.youtube.com/watch?v=Ucp0TTmvqOE,https://www.youtube.com/watch?v=Ucp0TTmvqOE,
ASU / Intel,Stratix-V 5SGSD8,Stratix-V,1.18E+11,int16/int8,19.1,Dataflow/FPGA,Inference,System,SE,,VGG-16,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://dl.acm.org/citation.cfm?id=2847276,
NUDT / Xilinx,Virtex7 XC7VX690T,Virtex7,2.22E+11,int16/int8,24.8,Dataflow/FPGA,Inference,System,SE,,Alexnet,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://ieeexplore.ieee.org/document/7929190,
Imperial College,Xilinx XC7Z020,Zynq-020,1.27E+10,int16,1.75,Dataflow/FPGA,Inference,System,SE,,,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://dl.acm.org/citation.cfm?id=3021791,
Tsinghua / Xilinx,Xilinx Zynq XC7Z045,Zynq-045,1.37E+11,int16,9.63,Dataflow/FPGA,Inference,System,SE,,VGG-16SVD,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://dl.acm.org/citation.cfm?id=2847265,
Peking Univ / Xilinx,Xilinx XC7Z045,Zynq-045,2.30E+11,int16,9.4,Dataflow/FPGA,Inference,System,SE,,VGGNet-E,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://dl.acm.org/citation.cfm?id=3062244,
Peking Univ / UCLA / Xilinx,Xilinx XC7VX690T,Virtex7,3.54E+11,int16,26,Dataflow/FPGA,Inference,System,SE,,VGG-16,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://ieeexplore.ieee.org/document/7966671,
Peking Univ / UCLA / Intel,Stratix-V 5SGSMD5,Stratix-V,3.64E+11,int16,25,Dataflow/FPGA,Inference,System,SE,,VGG-19,2/11/19,Imagenet data set,https://arxiv.org/abs/1712.08934v3;https://ieeexplore.ieee.org/document/7966671,
Fudan Univ / Xilinx,Xilinx XC7VX690T,Virtex7,5.66E+11,int16,30.2,Dataflow/FPGA,Inference,System,SE,,Alexnet,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://ieeexplore.ieee.org/document/7577308,
NUDT / Xilinx,Xilinx XC7VX690T,Virtex7,4.31E+11,int16,25,Dataflow/FPGA,Inference,System,SE,,C3D,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://dl.acm.org/citation.cfm?id=3174257,
NUDT / Xilinx,Xilinx XCVU440,Xilinx-440,7.85E+11,int16,26,Dataflow/FPGA,Inference,System,SE,,C3D,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://dl.acm.org/citation.cfm?id=3174257,
Peking Univ / UCLA / Xilinx,Xilinx XC7VX485T,XC-485T,7.26E+09,float,19.63,Dataflow/FPGA,Inference,System,SE,,LSTM-RNN (PRETRANS-3L-250H),2/11/19,,https://arxiv.org/abs/1712.08934v3;https://ieeexplore.ieee.org/document/7858394,
Peking Univ / UCLA / Xilinx,Xilinx XC7VX485T,XC-485T,6.16E+10,float,18.61,Dataflow/FPGA,Inference,System,SE,,Alexnet,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://dl.acm.org/citation.cfm?id=2689060,
USC / Intel,Stratix V,Stratix-V,1.24E+11,float,13.18,Dataflow/FPGA,Inference,System,SE,,VGG-16,2/11/19,,https://arxiv.org/abs/1712.08934v3;https://dl.acm.org/citation.cfm?id=3021727,