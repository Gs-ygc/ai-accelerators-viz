# 2019 IEEE-HPEC Paper Data


This page has a list of some of the data columns/fields that are included in the 2019 IEEE-HPEC paper: 

A. Reuther, P. Michaleas, M. Jones, V. Gadepally, S. Samsi and J. Kepner, "Survey and Benchmarking of Machine Learning Accelerators," *2019 IEEE High Performance Extreme Computing Conference (HPEC)*, 2019, pp. 1-9, \[[IEEE Xplore doi:: 10.1109/HPEC.2019.8916327](https://doi.org/10.1109/HPEC.2019.8916327)\] \[[ArXiv.org/abs/1908.11348](https://arxiv.org/abs/1908.11348)\].


For the full dataset in CSV format, please download \[[peak_accelerators_ieee_hpec_2019.csv](peak_accelerators_ieee_hpec_2019.csv)\]. 

---

| Company | Product | Label | Peak Perf. (GOPs/ GFLOPs) | Peak Power (W) | Precision | Form Factor | References | 
| ------- | ------- | ----- | :-----------------------: | :------------: | :-------: | :---------: | ---------- | 
| NVIDIA | Tesla K80 | K80 | 8740 | 300 | float | Card | \[[www.anandtech.com](https://www.anandtech.com/show/8729/nvidia-launches-tesla-k80-gk210-gpu)\] | 
| NVIDIA | Pascal NVMe | P100 | 21200 | 300 | half | Card | \[[www.nvidia.com](https://www.nvidia.com/en-us/data-center/tesla-p100/)\]  \[[www.anandtech.com](https://www.anandtech.com/show/12809/16gb-nvidia-tesla-v100-gets-reprieve-remains-in-production)\] | 
| NVIDIA | Volta NVMe | V100 | 125000 | 300 | AI | Card | \[[www.nvidia.com](https://www.nvidia.com/en-us/data-center/tesla-v100/)\]  \[[www.anandtech.com](https://www.anandtech.com/show/12809/16gb-nvidia-tesla-v100-gets-reprieve-remains-in-production)\] | 
| NVIDIA | DGX-1 | DGX-1 | 960000 | 3500 | AI | System | \[[www.anandtech.com](https://www.anandtech.com/show/12587/nvidias-dgx2-sixteen-v100-gpus-30-tb-of-nvme-only-400k)\] | 
| NVIDIA | DGX-2 | DGX-2 | 1.92e+06 | 10000 | AI | System | \[[www.anandtech.com](https://www.anandtech.com/show/12587/nvidias-dgx2-sixteen-v100-gpus-30-tb-of-nvme-only-400k)\] | 
| NVIDIA | DGX Station | DGX-Station | 480000 | 1500 | AI | System | \[[clustervision.com](https://clustervision.com/solutions/cluster-design/nvidia-dgx-station/)\] | 
| NVIDIA | Jetson1 | Jetson1 | 408 | 11.7 | AI | System | \[[devblogs.nvidia.com](https://devblogs.nvidia.com/jetson-tx2-delivers-twice-intelligence-edge/)\] | 
| NVIDIA | Jetson2 | Jetson2 | 580 | 12.8 | AI | System | \[[devblogs.nvidia.com](https://devblogs.nvidia.com/jetson-tx2-delivers-twice-intelligence-edge/)\] | 
| NVIDIA | Jetson Xavier | Xavier | 10000 | 30 | half | System | \[[www.extremetech.com](https://www.extremetech.com/computing/270681-nvidias-jetson-xavier-stuffs-volta-performance-into-tiny-form-factor)\] | 
| NVIDIA | Turing Quadro RTX 6000 | Turing | 131000 | 260 | int8 | Card | \[[devblogs.nvidia.com](https://devblogs.nvidia.com/nvidia-turing-architecture-in-depth/)\] | 
| GraphCore | C2 | GraphCoreC2 | 5000 | 300 | AI | Card | \[[www.graphcore.ai](https://www.graphcore.ai/posts/preliminary-ipu-benchmarks-providing-previously-unseen-performance-for-a-range-of-machine-learning-applications)\]  \[[github.com](https://github.com/albanie/convnet-burden)\] | 
| GraphCore | C2 | GraphCoreNode | 32000 | 2400 | AI | System | \[[www.graphcore.ai](https://www.graphcore.ai/posts/preliminary-ipu-benchmarks-providing-previously-unseen-performance-for-a-range-of-machine-learning-applications)\]  \[[github.com](https://github.com/albanie/convnet-burden)\] | 
| Wave Computing | DPU | Wave DPU | 180000 | 300 | AI | Card | \[[www.nextplatform.com](https://www.nextplatform.com/2017/08/23/first-depth-view-wave-computings-dpu-architecture-systems/)\]  \[[github.com](https://github.com/albanie/convnet-burden)\] | 
| Wave Computing | DPU | Wave System | 2.9e+06 | 2700 | AI | System | \[[www.top500.org](https://www.top500.org/news/wave-computing-launches-machine-learning-appliance/)\]  \[[github.com](https://github.com/albanie/convnet-burden)\] | 
| Intel | Xeon Phi 7210F | Phi7210F | 2660 | 230 | double | Chip | \[[en.wikipedia.org](https://en.wikipedia.org/wiki/Xeon_Phi)\] | 
| Intel | Xeon Phi 7290F | Phi7290F | 3460 | 260 | double | Chip | \[[en.wikipedia.org](https://en.wikipedia.org/wiki/Xeon_Phi)\] | 
| Intel | Xeon Skylake SP (Scalable) | 2xSkylakeSP | 2620 | 410 | float | Chip | \[[software.intel.com](https://software.intel.com/en-us/articles/intel-processors-for-deep-learning-training)\]  \[[ark.intel.com](https://ark.intel.com/products/120496/Intel-Xeon-Platinum-8180-Processor-38-5M-Cache-2-50-GHz-)\] | 
| Intel | Nervana Lake Crest | Nervana1 | 38000 | 210 | float | Card | \[[newsroom.intel.com](https://newsroom.intel.com/editorials/artificial-intelligence-requires-holistic-approach/)\]  \[[www.hpcwire.com](https://www.hpcwire.com/2018/05/24/intel-pledges-first-commercial-nervana-product-spring-crest-in-2019/)\]  \[[www.top500.org](https://www.top500.org/news/intel-lays-out-new-roadmap-for-ai-portfolio/)\] | 
| Intel | Nervana NNP L-1000 (Spring Crest) | Nervana2 | 120000 | 210 | AI | Card | \[[newsroom.intel.com](https://newsroom.intel.com/editorials/artificial-intelligence-requires-holistic-approach/)\]  \[[www.hpcwire.com](https://www.hpcwire.com/2018/05/24/intel-pledges-first-commercial-nervana-product-spring-crest-in-2019/)\]  \[[www.top500.org](https://www.top500.org/news/intel-lays-out-new-roadmap-for-ai-portfolio/)\] | 
| Intel | Movidius Myriad X | MovidiusX | 1000 | 2 | int16 | Chip | \[[www.extremetech.com](https://www.extremetech.com/computing/254772-new-movidius-myriad-x-vpu-packs-custom-neural-compute-engine)\]  \[[thenewstack.io](https://thenewstack.io/a-closer-look-at-intel-movidius-neural-compute-stick/)\] | 
| Intel | Arria 10 1150 | Arria | 283000 | 85 | AI | Chip | \[[arxiv.org](https://arxiv.org/abs/1807.06434)\]  \[[www.nextplatform.com](https://www.nextplatform.com/2018/07/31/intel-fpga-architecture-focuses-on-deep-learning-inference/)\] | 
| Habana | Goya HL-1000 | Goya | 57000 | 100 | AI | Chip | \[[www.top500.org](https://www.top500.org/news/ai-startup-sets-high-water-mark-with-new-inference-accelerator/)\]  \[[www.cv-foundation.org](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\] | 
| Google | TPU1 | TPU1 | 23000 | 40 | int16 | Chip | \[[www.nextplatform.com](https://www.nextplatform.com/2018/05/10/tearing-apart-googles-tpu-3-0-ai-coprocessor/)\] | 
| Google | TPU2 | TPU2 | 45000 | 250 | AI | Chip | \[[www.nextplatform.com](https://www.nextplatform.com/2018/05/10/tearing-apart-googles-tpu-3-0-ai-coprocessor/)\] | 
| Google | TPU3 | TPU3 | 90000 | 200 | AI | Chip | \[[www.nextplatform.com](https://www.nextplatform.com/2018/05/10/tearing-apart-googles-tpu-3-0-ai-coprocessor/)\] | 
| Google | TPU Edge | TPUedge | 58.5 | 2 | AI | System | \[[aiyprojects.withgoogle.com](https://aiyprojects.withgoogle.com/edge-tpu)\] | 
| MIT | Eyeriss | Eyeriss | 32.7 | 0.45 | AI | Chip | \[[ieeexplore.ieee.org](https://ieeexplore.ieee.org/document/7738524)\]  \[[github.com](https://github.com/albanie/convnet-burden)\] | 
| IBM | TrueNorth | TrueNorth | 1890 | 0.5 | int8 | System | \[[www.top500.org](https://www.top500.org/news/ibm-finds-killer-app-for-truenorth-neuromorphic-chip/)\]  \[[github.com](https://github.com/albanie/convnet-burden)\] | 
| IBM | TrueNorth | TrueNorth | 1890 | 44 | int8 | System | \[[www.top500.org](https://www.top500.org/news/ibm-finds-killer-app-for-truenorth-neuromorphic-chip/)\]  \[[github.com](https://github.com/albanie/convnet-burden)\] | 
| Rockchip | RK3399Pro | RK3399Pro | 2400 | 3 | 8bit | Chip | \[[www.rock-chips.com](http://www.rock-chips.com/a/en/News/Press_Releases/2018/0108/869.html)\]  \[[www.cnx-software.com](https://www.cnx-software.com/2018/01/08/rockchip-rk3399pro-soc-integrates-a-2-4-tops-neural-network-processing-unit-for-artificial-intelligence-applications/)\] | 
| Baidu | Baidu Kunlun 818-300 | Baidu | 260000 | 100 | AI | Chip | \[[www.eetimes.com](https://www.eetimes.com/document.asp?doc_id=1333449)\]  \[[www.zdnet.com](https://www.zdnet.com/article/baidu-creates-kunlun-silicon-for-ai/)\] | 
| AIStorm | AIStorm | AIStorm | 2500 | 0.227 | int8 | Chip | \[[www.eetimes.com](https://www.eetimes.com/document.asp?doc_id=1334301)\] | 
| Xilinx / Tokyo Tech | Zynq XC7Z020 | Zynq-020 | 330 | 2.3 | 1-bit | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[ieeexplore.ieee.org](https://ieeexplore.ieee.org/document/8056771)\] | 
| Intel / Univ Sydney | GX1155 | GX1155 | 40800 | 48 | 1-bit | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[ieeexplore.ieee.org](https://ieeexplore.ieee.org/document/8056823)\] | 
| Fudan Univ | Zynq XC7Z020 | Zynq-020 | 410 | 2.26 | 2-bit | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[ieeexplore.ieee.org](https://ieeexplore.ieee.org/document/8056820)\] | 
| Xilinx / Tsinghua U | Zynq XC7Z020 | Zynq-020 | 84.3 | 3.5 | int8 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[ieeexplore.ieee.org](https://ieeexplore.ieee.org/document/7930521)\] | 
| ASU / Intel | Intel Arria 10 GX1150 | Arria 10 | 645 | 21.2 | int16/int8 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[dl.acm.org](https://dl.acm.org/citation.cfm?id=3021736)\] | 
| DeePhi / Stanford / Xilinx | Xilinx XCKU060 | Zynq-060 | 2520 | 41 | int16/int12 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[dl.acm.org](https://dl.acm.org/citation.cfm?id=3021745)\] | 
| Peking Univ / UCLA / Xilinx | Xilinx XC7Z020 + XCV7VX620Tx6 | XilinxCluster | 1280 | 160 | int16 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[dl.acm.org](https://dl.acm.org/citation.cfm?id=2934644)\] | 
| Univ Wisconsin / Intel | Intel Arria 10 GX1150 | Arria 10 | 1790 | 37.46 | int16 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[dl.acm.org](https://dl.acm.org/citation.cfm?id=3021698)\] | 
| Peking Univ / Xilinx | Xilinx ZCU102 | ZCU102 | 2940 | 23.6 | int16 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[ieeexplore.ieee.org](https://ieeexplore.ieee.org/document/7966660)\] | 
| Intel | Intel Arria 10 GX1150 | Arria 10 | 1380 | 45 | fp16 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[dl.acm.org](https://dl.acm.org/citation.cfm?id=3021738)\] | 
| USC / Intel | Stratix-V | Stratix-V | 229 | 8.04 | int32 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[ieeexplore.ieee.org](https://ieeexplore.ieee.org/document/7995253)\] | 
| Univ Wisconsin / Intel | Intel Arria 10 GX1150 | Arria 10 | 866 | 41.73 | float | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[dl.acm.org](https://dl.acm.org/citation.cfm?id=3021698)\] | 
| Cambricon | Cambricon MLU-100 | Cambricon | 166000 | 110 | int8 | Chip | \[[www.anandtech.com](https://www.anandtech.com/show/12815/cambricon-makers-of-huaweis-kirin-npu-ip-build-a-big-ai-chip-and-pcie-card)\]  \[[ieeexplore.ieee.org](https://ieeexplore.ieee.org/document/7551409)\] | 
| Cambricon | Cambricon MLU-100 | Cambricon | 83200 | 110 | fp16 | Chip | \[[www.anandtech.com](https://www.anandtech.com/show/12815/cambricon-makers-of-huaweis-kirin-npu-ip-build-a-big-ai-chip-and-pcie-card)\]  \[[ieeexplore.ieee.org](https://ieeexplore.ieee.org/document/7551409)\] | 
| DianNao | DianNao | DianNao | 452 | 0.485 | int16 | Chip | \[[cacm.acm.org](https://cacm.acm.org/magazines/2016/11/209123-diannao-family/)\] | 
| DianNao | DaDianNao | DaDianNao | 5590 | 15.97 | int16 | Chip | \[[cacm.acm.org](https://cacm.acm.org/magazines/2016/11/209123-diannao-family/)\] | 
| DianNao | ShiDianNao | ShiDianNao | 194 | 0.32 | int16 | Chip | \[[cacm.acm.org](https://cacm.acm.org/magazines/2016/11/209123-diannao-family/)\] | 
| DianNao | PuDianNao | PuDianNao | 1060 | 0.596 | int16 | Chip | \[[cacm.acm.org](https://cacm.acm.org/magazines/2016/11/209123-diannao-family/)\] | 
| Apple | Apple A12 Neural Engine | A12 | 624 | 5.5 | int8 | System | \[[www.anandtech.com](https://www.anandtech.com/show/13392/the-iphone-xs-xs-max-review-unveiling-the-silicon-secrets/5)\]  \[[medium.com](https://medium.com/syncedreview/ai-chip-duel-apple-a12-bionic-vs-huawei-kirin-980-ec29cfe68632)\] | 
| Qualcomm | Snapdragon 845 | S845 | 200 | 5.01 | int8 | System | \[[www.anandtech.com](https://www.anandtech.com/show/12520/the-galaxy-s9-review/6)\] | 
| QualComm | Snapdragon 835 | S835 | 130 | 3.79 | int8 | System | \[[www.anandtech.com](https://www.anandtech.com/show/12520/the-galaxy-s9-review/6)\] | 
| Huawei | Kirin 970 (Mali--75) | Mali-75 | 261 | 6.33 | int8 | System | \[[www.anandtech.com](https://www.anandtech.com/show/12520/the-galaxy-s9-review/6)\] | 
| Huawei | Kirin 980 (Mali-76) | Mali-76 | 468 | 5 | int8 | System | \[[www.anandtech.com](https://www.anandtech.com/show/13298/hisilicon-announces-the-kirin-980-first-a76-g76-on-7nm/2)\] | 
| Groq | Groq | Groq | 400000 | 300 | int16 | Card | \[[www.electronicdesign.com](https://www.electronicdesign.com/industrial-automation/groq-outlines-potential-power-artificial-intelligence-chip)\] | 
| AMD | Radeon Instinct MI60 | AMD-MI60 | 29500 | 300 | fp16 | Card | \[[www.amd.com](https://www.amd.com/en/graphics/servers-radeon-instinct-mi)\] | 
| AMD | Radeon Instinct MI6 | AMD-MI6 | 5730 | 150 | fp16 | Card | \[[www.amd.com](https://www.amd.com/en/graphics/servers-radeon-instinct-mi)\] | 
| Tesla | Tesla Full Self-Driving Computer | Tesla | 72000 | 72 | int8 |  | \[[www.youtube.com](https://www.youtube.com/watch?v=Ucp0TTmvqOE)\] | 
| ASU / Intel | Stratix-V 5SGSD8 | Stratix-V | 118 | 19.1 | int16/int8 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[dl.acm.org](https://dl.acm.org/citation.cfm?id=2847276)\] | 
| NUDT / Xilinx | Virtex7 XC7VX690T | Virtex7 | 222 | 24.8 | int16/int8 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[ieeexplore.ieee.org](https://ieeexplore.ieee.org/document/7929190)\] | 
| Imperial College | Xilinx XC7Z020 | Zynq-020 | 12.7 | 1.75 | int16 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[dl.acm.org](https://dl.acm.org/citation.cfm?id=3021791)\] | 
| Tsinghua / Xilinx | Xilinx Zynq XC7Z045 | Zynq-045 | 137 | 9.63 | int16 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[dl.acm.org](https://dl.acm.org/citation.cfm?id=2847265)\] | 
| Peking Univ / Xilinx | Xilinx XC7Z045 | Zynq-045 | 230 | 9.4 | int16 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[dl.acm.org](https://dl.acm.org/citation.cfm?id=3062244)\] | 
| Peking Univ / UCLA / Xilinx | Xilinx XC7VX690T | Virtex7 | 354 | 26 | int16 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[ieeexplore.ieee.org](https://ieeexplore.ieee.org/document/7966671)\] | 
| Peking Univ / UCLA / Intel | Stratix-V 5SGSMD5 | Stratix-V | 364 | 25 | int16 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[ieeexplore.ieee.org](https://ieeexplore.ieee.org/document/7966671)\] | 
| Fudan Univ / Xilinx | Xilinx XC7VX690T | Virtex7 | 566 | 30.2 | int16 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[ieeexplore.ieee.org](https://ieeexplore.ieee.org/document/7577308)\] | 
| NUDT / Xilinx | Xilinx XC7VX690T | Virtex7 | 431 | 25 | int16 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[dl.acm.org](https://dl.acm.org/citation.cfm?id=3174257)\] | 
| NUDT / Xilinx | Xilinx XCVU440 | Xilinx-440 | 785 | 26 | int16 | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[dl.acm.org](https://dl.acm.org/citation.cfm?id=3174257)\] | 
| Peking Univ / UCLA / Xilinx | Xilinx XC7VX485T | XC-485T | 7.26 | 19.63 | float | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[ieeexplore.ieee.org](https://ieeexplore.ieee.org/document/7858394)\] | 
| Peking Univ / UCLA / Xilinx | Xilinx XC7VX485T | XC-485T | 61.6 | 18.61 | float | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[dl.acm.org](https://dl.acm.org/citation.cfm?id=2689060)\] | 
| USC / Intel | Stratix V | Stratix-V | 124 | 13.18 | float | System | \[[arxiv.org](https://arxiv.org/abs/1712.08934v3)\]  \[[dl.acm.org](https://dl.acm.org/citation.cfm?id=3021727)\] | 

---


Copyright 2021 MIT, Albert I. Reuther